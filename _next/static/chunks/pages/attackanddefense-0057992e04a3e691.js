(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[928],{8119:function(e,t,n){(window.__NEXT_P=window.__NEXT_P||[]).push(["/attackanddefense",function(){return n(7013)}])},7013:function(e,t,n){"use strict";n.r(t),n.d(t,{default:function(){return m}});var a=n(5893),i=n(3078),o=n(8008),r=n(8207),s=n(929),c=n(4410),l=n(2290),d=n.n(l);function m(){return(0,a.jsxs)(i.W,{children:[(0,a.jsx)(o.D,{order:1,className:d().pagetitle,children:"Attacks"}),(0,a.jsxs)(r.K,{bg:"var(--mantine-color-body)",gap:"sm",children:[(0,a.jsx)(s.E,{src:"attacks.png",alt:"attacks",radius:"md",h:"auto",w:"100%",fit:"contain"}),(0,a.jsx)(c.x,{ta:"center",c:"dimmed",children:"Figure 5. The taxonomy of privacy-related attack methods for LLMs."}),(0,a.jsx)(c.x,{fw:700,children:"Takeaways (Data Extraction):"}),(0,a.jsx)(c.x,{children:"The effectiveness of data extraction attacks depends on several factors: the inherent memorization ability of language models (e.g., scaled with model size), the strategic crafting of prompts (e.g., context length and the use of jailbreaking prompts), and training data distribution (like repeated or poisoned data). While alignment techniques are successful in guiding LLMs to avoid producing sensitive information, they do not eliminate memorization and can be easily bypassed using jailbreaking prompts."}),(0,a.jsx)(c.x,{fw:700,children:"Takeaways (MIA):"}),(0,a.jsx)(c.x,{children:"Membership inference attacks could happen in different stages of LLM lifecycle despite the number of member/training samples. When attacking LLMs, using difficulty calibration is more effective than merely thresholding the outputs of LLMs."}),(0,a.jsx)(c.x,{fw:700,children:"Takeaways (Jailbreaking):"}),(0,a.jsx)(c.x,{children:"Manually crafted jailbreaking prompts, although straightforward and convenient to use, tend to lose their effectiveness rapidly due to the swift evolution of LLMs. In contrast, methods that automatically generate jailbreaking prompts offer greater resilience against these updates, albeit at the cost of increased computational demands."})]}),(0,a.jsx)(o.D,{order:1,className:d().pagetitle,children:"Defenses"}),(0,a.jsxs)(r.K,{bg:"var(--mantine-color-body)",gap:"sm",children:[(0,a.jsx)(s.E,{src:"defenses.png",alt:"defenses",radius:"md",h:"auto",w:"100%",fit:"contain"}),(0,a.jsx)(c.x,{ta:"center",c:"dimmed",children:"Figure 6. The taxonomy of privacy-related defense methods for LLM."}),(0,a.jsx)(c.x,{fw:700,children:"Takeaways:"}),(0,a.jsx)(c.x,{children:"Implementing exact machine unlearning in LLMs necessitates altering their training process, a strategy currently impractical due to the substantial computational demands of these models. In contrast, approximate machine unlearning presents a more feasible approach, typically accomplished by fine-tuning the LLMs with a specific, tailored objective."})]})]})}},2290:function(e){e.exports={pagetitle:"common_pagetitle__4xBA6",block_orange:"common_block_orange__1r4bT",block_red:"common_block_red__sfVw_",block_green:"common_block_green__4w83L",block_blue:"common_block_blue__Ru_Ps",bibtext:"common_bibtext__b6Cmh"}},929:function(e,t,n){"use strict";n.d(t,{E:function(){return h}});var a=n(7294),i=n(9429),o=n(3637),r=n(987),s=n(9581),c=n(8952),l=n(3362),d={root:"m-9e117634"};let m={},f=(0,o.Z)((e,{radius:t,fit:n})=>({root:{"--image-radius":void 0===t?void 0:(0,i.H5)(t),"--image-object-fit":n}})),h=(0,l.b)((e,t)=>{let n=(0,r.w)("Image",m,e),{classNames:i,className:o,style:l,styles:h,unstyled:u,vars:g,onError:p,src:b,radius:x,fit:_,fallbackSrc:k,...y}=n,[w,v]=(0,a.useState)(!b);(0,a.useEffect)(()=>v(!b),[b]);let j=(0,s.y)({name:"Image",classes:d,props:n,className:o,style:l,classNames:i,styles:h,unstyled:u,vars:g,varsResolver:f});return w&&k?a.createElement(c.x,{component:"img",src:k,...j("root"),onError:p,mod:"fallback",...y}):a.createElement(c.x,{component:"img",ref:t,...j("root"),src:b,onError:e=>{p?.(e),v(!0)},...y})});h.classes=d,h.displayName="@mantine/core/Image"},8207:function(e,t,n){"use strict";n.d(t,{K:function(){return h}});var a=n(7294),i=n(9429),o=n(3637),r=n(987),s=n(9581),c=n(8952),l=n(9535),d={root:"m-6d731127"};let m={gap:"md",align:"stretch",justify:"flex-start"},f=(0,o.Z)((e,{gap:t,align:n,justify:a})=>({root:{"--stack-gap":(0,i.bG)(t),"--stack-align":n,"--stack-justify":a}})),h=(0,l.d)((e,t)=>{let n=(0,r.w)("Stack",m,e),{classNames:i,className:o,style:l,styles:h,unstyled:u,vars:g,align:p,justify:b,gap:x,variant:_,...k}=n,y=(0,s.y)({name:"Stack",props:n,classes:d,className:o,style:l,classNames:i,styles:h,unstyled:u,vars:g,varsResolver:f});return a.createElement(c.x,{ref:t,...y("root"),variant:_,...k})});h.classes=d,h.displayName="@mantine/core/Stack"},8008:function(e,t,n){"use strict";n.d(t,{D:function(){return u}});var a=n(7294),i=n(3637),o=n(987),r=n(9581),s=n(8952),c=n(9535),l=n(8565);let d=["h1","h2","h3","h4","h5","h6"];var m={root:"m-8a5d1357"};let f={order:1},h=(0,i.Z)((e,{order:t,size:n,lineClamp:a})=>{let i=function(e,t){let n=void 0!==t?t:`h${e}`;return d.includes(n)?{fontSize:`var(--mantine-${n}-font-size)`,fontWeight:`var(--mantine-${n}-font-weight)`,lineHeight:`var(--mantine-${n}-line-height)`}:{fontSize:(0,l.h)(n),fontWeight:`var(--mantine-h${e}-font-weight)`,lineHeight:`var(--mantine-h${e}-line-height)`}}(t,n);return{root:{"--title-fw":i.fontWeight,"--title-lh":i.lineHeight,"--title-fz":i.fontSize,"--title-line-clamp":"number"==typeof a?a.toString():void 0}}}),u=(0,c.d)((e,t)=>{let n=(0,o.w)("Title",f,e),{classNames:i,className:c,style:l,styles:d,unstyled:u,order:g,vars:p,size:b,variant:x,lineClamp:_,...k}=n,y=(0,r.y)({name:"Title",props:n,classes:m,className:c,style:l,classNames:i,styles:d,unstyled:u,vars:p,varsResolver:h});return[1,2,3,4,5,6].includes(g)?a.createElement(s.x,{...y("root"),component:`h${g}`,variant:x,ref:t,mod:{order:g,"data-line-clamp":"number"==typeof _},size:b,...k}):null});u.classes=m,u.displayName="@mantine/core/Title"}},function(e){e.O(0,[774,888,179],function(){return e(e.s=8119)}),_N_E=e.O()}]);